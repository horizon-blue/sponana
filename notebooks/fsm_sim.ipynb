{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydrake.all import (\n",
    "    RigidTransform,\n",
    "    RotationMatrix,\n",
    "    StartMeshcat,\n",
    "    RandomGenerator,\n",
    "    Diagram,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "import sponana.utils\n",
    "from sponana.planner.rrt import SpotProblem, rrt_planning\n",
    "from sponana.planner.navigator import Navigator\n",
    "from sponana.fsm.finite_state_machine import FiniteStateMachine\n",
    "import sponana.sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7010\n"
     ]
    }
   ],
   "source": [
    "# Start the visualizer.\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:drake:RenderEngineVtk only supports Mesh/Convex specifications which use .obj and .gltf files. Mesh specifications using other mesh types (e.g., .stl, .dae, etc.) will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_sample [-0.1   0.05]\n",
      "y_sample [-2.00000000e-01  2.77555756e-17]\n",
      "appended: x_points_append: [0.04999999999999999] y_points_append: [2.7755575615628914e-17]\n",
      "dist 0.15\n",
      "appended: x_points_append: [0.04999999999999999, -0.1] y_points_append: [2.7755575615628914e-17, 2.7755575615628914e-17]\n",
      "dist 0.0\n",
      "dist 0.2\n",
      "dist 0.25\n",
      "appended: x_points_append: [0.04999999999999999, -0.1, 0.04999999999999999] y_points_append: [2.7755575615628914e-17, 2.7755575615628914e-17, -0.19999999999999998]\n",
      "x_sample [-0.1   0.05]\n",
      "y_sample [-2.00000000e-01  2.77555756e-17]\n",
      "appended: x_points_append: [-0.1] y_points_append: [-0.19999999999999998]\n",
      "x_sample [-0.1   0.05]\n",
      "y_sample [-2.00000000e-01  2.77555756e-17]\n",
      "appended: x_points_append: [0.04999999999999999] y_points_append: [2.7755575615628914e-17]\n",
      "dist 0.2\n",
      "appended: x_points_append: [0.04999999999999999, 0.04999999999999999] y_points_append: [2.7755575615628914e-17, -0.19999999999999998]\n",
      "dist 0.15\n",
      "dist 0.25\n",
      "appended: x_points_append: [0.04999999999999999, 0.04999999999999999, -0.1] y_points_append: [2.7755575615628914e-17, -0.19999999999999998, 2.7755575615628914e-17]\n",
      "x_sample [-0.1   0.05]\n",
      "y_sample [-2.00000000e-01  2.77555756e-17]\n",
      "appended: x_points_append: [0.04999999999999999] y_points_append: [2.7755575615628914e-17]\n",
      "dist 0.0\n",
      "dist 0.0\n",
      "dist 0.2\n",
      "appended: x_points_append: [0.04999999999999999, 0.04999999999999999] y_points_append: [2.7755575615628914e-17, -0.19999999999999998]\n",
      "dist 0.0\n",
      "dist 0.25\n",
      "dist 0.15\n",
      "appended: x_points_append: [0.04999999999999999, 0.04999999999999999, -0.1] y_points_append: [2.7755575615628914e-17, -0.19999999999999998, -0.19999999999999998]\n",
      "[TableSceneSpec(has_banana=False, banana_contact_params=None, n_objects=3, object_type_indices=array([0, 1, 1]), object_contact_params=[(0.04999999999999999, 2.7755575615628914e-17, 4.841921954315102, 0), (-0.1, 2.7755575615628914e-17, 1.657078340818876, 0), (0.04999999999999999, -0.19999999999999998, 5.721221562775121, 0)]), TableSceneSpec(has_banana=True, banana_contact_params=(-0.1, -0.19999999999999998, 1.781642008465248, 2), n_objects=3, object_type_indices=array([1, 0, 1]), object_contact_params=[(0.04999999999999999, 2.7755575615628914e-17, 0.925411991541767, 2), (0.04999999999999999, -0.19999999999999998, 4.075456308009082, 2), (-0.1, 2.7755575615628914e-17, 4.303231926064594, 0)]), TableSceneSpec(has_banana=False, banana_contact_params=None, n_objects=3, object_type_indices=array([5, 1, 5]), object_contact_params=[(0.04999999999999999, 2.7755575615628914e-17, 3.1759528834447694, 0), (0.04999999999999999, -0.19999999999999998, 3.0221099894534897, 2), (-0.1, -0.19999999999999998, 5.086347867217728, 2)])]\n",
      "Press Space to log system info\n",
      "banana_table_idx 1\n",
      "spec[banana_table_idx].has_banana True\n",
      "do_rrt retrieval 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==== LCM Warning ===\n",
      "LCM detected that large packets are being received, but the kernel UDP\n",
      "receive buffer is very small.  The possibility of dropping packets due to\n",
      "insufficient buffer space is very high.\n",
      "\n",
      "For more information, visit:\n",
      "   http://lcm-proj.github.io/lcm/multicast_setup.html\n",
      "\n",
      "==== LCM Warning ===\n",
      "LCM detected that large packets are being received, but the kernel UDP\n",
      "receive buffer is very small.  The possibility of dropping packets due to\n",
      "insufficient buffer space is very high.\n",
      "\n",
      "For more information, visit:\n",
      "   http://lcm-proj.github.io/lcm/multicast_setup.html\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "check_banana retrieval 0\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n",
      "grasp_banana retrieval 0\n",
      "within get_camera_pose function check ______\n",
      "current_cam_ind: 0\n",
      "next_camera_pose: [ 1.     -2.5     0.2475]\n",
      "within _update_do_rrt function check ____\n",
      "current_cam_reached: [0.]\n",
      "check_banana: 0\n",
      "first_rrt_condition\n"
     ]
    }
   ],
   "source": [
    "meshcat.Delete()\n",
    "meshcat.DeleteAddedControls()\n",
    "rng = np.random.default_rng(145)  # this is for python\n",
    "generator = RandomGenerator(rng.integers(0, 1000))  # this is for c++\n",
    "\n",
    "# simulation_time = -1  # run indefinitely until ESC is pressed\n",
    "simulation_time = 2\n",
    "debug = True\n",
    "add_fixed_cameras = False\n",
    "use_teleop = False\n",
    "\n",
    "simulator, diagram = sponana.sim.clutter_gen(\n",
    "    meshcat,\n",
    "    rng,\n",
    "    debug=debug,\n",
    "    simulation_time=simulation_time,\n",
    "    add_fixed_cameras=add_fixed_cameras,\n",
    "    use_teleop=use_teleop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_do_rrt(current_cam_reached, current_cam_ind, check_banana):\n",
    "    \"\"\"\n",
    "    Function to update flag to indicate to RRT/Navigator for ready for planning/movement.\n",
    "    Inputs:\n",
    "    - from context,\n",
    "    current_cam_reached: int where 0 when camera is reached and 1 when not.\n",
    "\n",
    "    Returns:\n",
    "    - new_cam_reached: if current cam reached, switch to 0 so that navigator can plan again.\n",
    "    if current cam is not reached, stay 1 so that navigator will wait.\n",
    "    \"\"\"\n",
    "    do_rrt = 0\n",
    "    # just starting, have not reached the first camera pose, do_rrt to get to the first camera\n",
    "    if current_cam_reached == 0 and current_cam_ind == 0:\n",
    "        print(\"first if case\")\n",
    "        do_rrt = 1\n",
    "    # have reached camera, and banana has finished being checked\n",
    "    elif current_cam_reached == 1 and check_banana == 1:\n",
    "        print(\"second if case\")\n",
    "        do_rrt = 1\n",
    "    return do_rrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_camera_ind(current_cam_reached, see_banana, has_banana, current_cam_ind):\n",
    "    \"\"\"Function for updating camera pose list index.\n",
    "    Inputs:\n",
    "    - from context:\n",
    "    current_cam_reached: int where 0 when camera is reached and 1 when not.\n",
    "    see_banana: int where 0 when banana is not seen and 1 when banana seen.\n",
    "    has_banana: int where 0 when banana is grasped nad 1 when banana is not grasped.\n",
    "\n",
    "    Returns: None\n",
    "    If current camera is reached and no banana is seen/grasped, needs to continue to search\n",
    "    next camera pose, so current_cam_ind is incremented.\n",
    "    \"\"\"\n",
    "    new_camera_ind = current_cam_ind\n",
    "    if current_cam_reached == 1 and see_banana == 0 and has_banana == 0:\n",
    "        if current_cam_ind <= 2:\n",
    "            new_camera_ind = current_cam_ind + 1\n",
    "        # none viewpoints have bananas, so do it all again?\n",
    "        else:\n",
    "            new_camera_ind = 0\n",
    "\n",
    "    return new_camera_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_pose(current_cam_ind, camera_pose_list):\n",
    "    \"\"\"\n",
    "    Function to get the next camera pose for Spot to travel to in RRT\n",
    "    Inputs:\n",
    "    - from context:\n",
    "    current_cam_reached: int where 0 when camera is reached and 1 when not.\n",
    "    Returns:\n",
    "    - next camera pose\n",
    "    \"\"\"\n",
    "    next_camera_pose = camera_pose_list[current_cam_ind]\n",
    "    return next_camera_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_check_banana(current_cam_reached, see_banana, has_banana):\n",
    "    \"\"\"Function as indicater for perception module.\n",
    "    Inputs:\n",
    "    - from context:\n",
    "    current_cam_reached: int where 0 when camera is reached and 1 when not.\n",
    "    see_banana: int where 0 when banana is not seen and 1 when banana seen.\n",
    "    has_banana: int where 0 when banana is grasped nad 1 when banana is not grasped.\n",
    "\n",
    "    Returns:\n",
    "    check_banana: if current_cam is reached, and banana is not seen, and banana is not grasped,\n",
    "    return 1 to call the perception module/system.\n",
    "    \"\"\"\n",
    "    check_banana = 0\n",
    "    if current_cam_reached == 1 and see_banana == 0 and has_banana == 0:\n",
    "        check_banana = 1\n",
    "    return check_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_grasp_banana(current_cam_reached, see_banana, has_banana):\n",
    "    \"\"\"Function as indicater for perception module.\n",
    "    Inputs:\n",
    "    - from context:\n",
    "    current_cam_reached: int where 0 when camera is reached and 1 when not.\n",
    "    see_banana: int where 0 when banana is not seen and 1 when banana seen.\n",
    "    has_banana: int where 0 when banana is grasped nad 1 when banana is not grasped.\n",
    "\n",
    "    Returns:\n",
    "    grasp_banana: if current_cam is reached, and banana is seen, and banana is not grasped,\n",
    "    return 1 to get banana grasped system.\n",
    "    \"\"\"\n",
    "    grasp_banana = 0\n",
    "    if current_cam_reached == 1 and see_banana == 1 and has_banana == 0:\n",
    "        grasp_banana = 1\n",
    "    return grasp_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_completion(has_banana):\n",
    "    completed = 0\n",
    "    if has_banana == 1:\n",
    "        completed = 1\n",
    "    return completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_call_perception(check_banana, current_cam_ind):\n",
    "    see_banana = 0\n",
    "    if check_banana == 1:\n",
    "        if current_cam_ind == 2:  # let's just pretend this is the one with banana\n",
    "            see_banana = 1\n",
    "            print(\"doing perception module:\" + \"found banana\")\n",
    "        else:\n",
    "            print(\"doing perception module:\" + \"banana not found\")\n",
    "    return see_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_call_grasp_banana(grasp_banana):\n",
    "    has_banana = 0\n",
    "    if grasp_banana == 1:\n",
    "        has_banana = 1\n",
    "        print(\"doing grasp module\")\n",
    "    return has_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize RRT output\n",
    "from manipulation.meshcat_utils import AddMeshcatTriad\n",
    "\n",
    "\n",
    "def visualize_path(path):\n",
    "    for i, pose in enumerate(path):\n",
    "        pose = RigidTransform(RotationMatrix.MakeZRotation(pose[2]), [*pose[:2], 0.0])\n",
    "        opacity = 0.2\n",
    "        AddMeshcatTriad(meshcat, f\"trajectory_{i}\", X_PT=pose, opacity=opacity)\n",
    "\n",
    "\n",
    "def delete_path(path):\n",
    "    for i, pose in enumerate(path):\n",
    "        meshcat.Delete(f\"trajectory_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pose = np.array([1.00000000e00, 1.50392176e-12, 3.15001955e00])\n",
    "q_start = initial_pose\n",
    "\n",
    "camera_pose0 = np.array([1, -2.5, 0.2475])\n",
    "camera_pose1 = np.array([1.00000000e00, 1.50392176e-12, 3.15001955e00])\n",
    "camera_pose2 = np.array([-2, -2, 0.2475])\n",
    "camera_pose_list = [camera_pose0, camera_pose1, camera_pose2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_rrt(q_goal):\n",
    "    print(\"q_sub_goal:\", q_goal, \"rrt done\")\n",
    "    current_cam_reached = 1\n",
    "    return current_cam_reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_do_rrt_unit_test():\n",
    "    current_cam_reached = 0\n",
    "    current_cam_ind = 0\n",
    "    check_banana = 0\n",
    "    check_do_rrt = update_do_rrt(current_cam_reached, current_cam_ind, check_banana)\n",
    "    if check_do_rrt == 1:\n",
    "        print(\"Camera not reached, ind = 0, need to do rrt, correct\")\n",
    "    current_cam_reached = 1\n",
    "    current_cam_ind = 0\n",
    "    check_banana = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigator = Navigator()\n",
    "\n",
    "\n",
    "def execute_finite_state_machine():\n",
    "    current_cam_reached = 0\n",
    "    current_cam_ind = 0\n",
    "    check_banana = 0\n",
    "    see_banana = 0\n",
    "    has_banana = 0\n",
    "    grasp_banana = 0\n",
    "    completed = 0  # update_completion(has_banana)\n",
    "    loop_count = 0\n",
    "    initial_pose = np.array([1.00000000e00, 1.50392176e-12, 3.15001955e00])\n",
    "    q_start = initial_pose\n",
    "    while completed == 0:\n",
    "        print(\"loop_count\", loop_count, \"_____\")\n",
    "        check_do_rrt = update_do_rrt(current_cam_reached, current_cam_ind, check_banana)\n",
    "        print(\"check do rrt\", check_do_rrt)\n",
    "        if check_do_rrt == 1:\n",
    "            # Do RRT\n",
    "            print(\"get pose\")\n",
    "            q_sub_goal = get_camera_pose(current_cam_ind, camera_pose_list)\n",
    "            spot_problem = SpotProblem(\n",
    "                q_start=q_start,\n",
    "                q_goal=q_sub_goal,\n",
    "                collision_checker=navigator._collision_check,\n",
    "            )\n",
    "            path = rrt_planning(spot_problem, 1000, 0.05)\n",
    "            # print(\"q_sub_goal:\", q_sub_goal, \"rrt done\")\n",
    "            # current_cam_reached = dummy_rrt(q_sub_goal)\n",
    "            print(\"q_start_pos:\", q_start, \"q_goal_post:\", q_sub_goal)\n",
    "            print(path)\n",
    "            print(\"visualizing path\")\n",
    "            visualize_path(path)\n",
    "            current_cam_reached = 1\n",
    "            q_start = q_sub_goal  # next q_start is now updated for the next loop.\n",
    "        check_banana = update_check_banana(current_cam_reached, see_banana, has_banana)\n",
    "        print(\"check_banana\", check_banana)\n",
    "        see_banana = dummy_call_perception(check_banana, current_cam_ind)\n",
    "        print(\"see_banana\", see_banana)\n",
    "        grasp_banana = update_grasp_banana(current_cam_reached, see_banana, has_banana)\n",
    "        print(\"grasp_banana\", grasp_banana)\n",
    "        has_banana = dummy_call_grasp_banana(grasp_banana)\n",
    "        print(\"has_banana\", has_banana)\n",
    "        current_cam_ind = update_camera_ind(\n",
    "            current_cam_reached, see_banana, has_banana, current_cam_ind\n",
    "        )\n",
    "        print(\"new current_cam_ind\", current_cam_ind)\n",
    "        completed = update_completion(has_banana)\n",
    "        print(\"completed\", completed)\n",
    "        # check_banana = 0\n",
    "        loop_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_finite_state_machine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_drake_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
